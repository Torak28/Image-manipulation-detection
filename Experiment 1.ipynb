{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cel\n",
    "\n",
    " * lepiej uczyć od warstwy FC czy razem z nią?\n",
    " * Najlepszy pooling\n",
    " * Najlepsza funkcja straty\n",
    " * Najlepszy optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "CHANNELS = 3\n",
    "\n",
    "IMAGE_RESIZE = 224\n",
    "DENSE_LAYER_ACTIVATION = 'softmax'\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "\n",
    "STEPS_PER_EPOCH_TRAINING = 10\n",
    "STEPS_PER_EPOCH_VALIDATION = 10\n",
    "\n",
    "BATCH_SIZE_TRAINING = 32\n",
    "BATCH_SIZE_VALIDATION = 32\n",
    "\n",
    "BATCH_SIZE_TESTING = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP = [False, True]\n",
    "DATA_GEN = [False, True]\n",
    "RESNET50_POOLING = ['avg', 'max']\n",
    "OBJECTIVE_FUNCTION = ['mean_squared_error', 'categorical_crossentropy', 'sparse_categorical_crossentropy', 'binary_crossentropy']\n",
    "OPTIMIZER = ['sgd', 'adam', 'adadelta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exper1(top, pool, opt, loss, dataGen):\n",
    "    out = []\n",
    "    print(f'MODEL with:')\n",
    "    print(f'\\tinclude_top: {top}')\n",
    "    print(f'\\tpooling: {pool}')\n",
    "    print(f'\\toptimizer: {opt}')\n",
    "    print(f'\\tloss_func: {loss}')\n",
    "    print(f'\\tdata_gen: {dataGen}')\n",
    "    \n",
    "    # Model\n",
    "    model = Sequential()\n",
    "    model.add(ResNet50(include_top = top, pooling = pool, weights = 'imagenet'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
    "    model.layers[0].trainable = False\n",
    "    model.summary()\n",
    "    model.compile(optimizer = opt, loss = loss, metrics = LOSS_METRICS)\n",
    "    \n",
    "    # Data Gen\n",
    "    image_size = IMAGE_RESIZE\n",
    "    if dataGen:\n",
    "        data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    else:\n",
    "        data_generator = ImageDataGenerator(\n",
    "            shear_range=10,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            preprocessing_function=preprocess_input\n",
    "        )\n",
    "    \n",
    "    # Data\n",
    "    path = '../../MGU/Projekt/PS-Battles-master/' if os.name != 'nt' else '..\\..\\MGU\\Data\\PS-Battles-master'\n",
    "    slash = '/' if os.name != 'nt' else '\\\\'\n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        directory=path + slash + 'test' + slash,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_TRAINING,\n",
    "        class_mode='binary')\n",
    "\n",
    "    validation_generator = data_generator.flow_from_directory(\n",
    "        directory=path + slash + 'valid'+ slash,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_VALIDATION,\n",
    "        class_mode='binary') \n",
    "    \n",
    "    # Callbacks\n",
    "    cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n",
    "    cb_checkpointer = ModelCheckpoint(filepath = '../working/best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')\n",
    "    \n",
    "    # Fit\n",
    "    fit_history = model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "        callbacks=[cb_checkpointer, cb_early_stopper]\n",
    "    )\n",
    "    model.load_weights(\"../working/best.hdf5\")\n",
    "    name = 'DogsCats_Top_' + str(top) + '_Pool_' + pool + '_Opt_' + opt + '_Loss_' + loss + '_dataGen_' + str(dataGen)\n",
    "    model.save(name + '.h5')\n",
    "    \n",
    "    # Score v1\n",
    "    scoreRes = model.evaluate_generator(\n",
    "        generator=validation_generator\n",
    "    )\n",
    "    print(f'Accuracy = {scoreRes}')\n",
    "    tmp = {}\n",
    "    tmp[name] = scoreRes\n",
    "    out.append(tmp)\n",
    "    \n",
    "    # Score v2\n",
    "    plt.figure(1, figsize = (15,8)) \n",
    "    plt.subplot(221)  \n",
    "    plt.plot(fit_history.history['accuracy'])  \n",
    "    plt.plot(fit_history.history['val_accuracy'])  \n",
    "    plt.title('model accuracy')  \n",
    "    plt.ylabel('accuracy')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'valid']) \n",
    "    plt.subplot(222)  \n",
    "    plt.plot(fit_history.history['loss'])  \n",
    "    plt.plot(fit_history.history['val_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'valid']) \n",
    "    plt.show()\n",
    "    \n",
    "    # Show some predictions\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        directory = path + slash + 'show' + slash,\n",
    "        target_size = (image_size, image_size),\n",
    "        batch_size = BATCH_SIZE_TESTING,\n",
    "        class_mode = None,\n",
    "        shuffle = False,\n",
    "        seed = 123\n",
    "    )\n",
    "    test_generator.reset()\n",
    "    pred = model.predict_generator(test_generator, steps = len(test_generator), verbose = 1)\n",
    "    predicted_class_indices = np.argmax(pred, axis = 1)\n",
    "    TEST_DIR = path + slash + 'show' + slash\n",
    "    f, ax = plt.subplots(5, 5, figsize = (15, 15))\n",
    "    for i in range(0,25):\n",
    "        imgBGR = cv2.imread(TEST_DIR + test_generator.filenames[i])\n",
    "        imgRGB = cv2.cvtColor(imgBGR, cv2.COLOR_BGR2RGB)\n",
    "        # a if condition else b\n",
    "        predicted_class = \"Dog\" if predicted_class_indices[i] else \"Cat\"\n",
    "        ax[i//5, i%5].imshow(imgRGB)\n",
    "        ax[i//5, i%5].axis('off')\n",
    "        ax[i//5, i%5].set_title(\"Predicted:{}\".format(predicted_class))    \n",
    "    plt.show()\n",
    "    \n",
    "    # End\n",
    "    print('---KONIEC---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False avg sgd mean_squared_error\n",
      "False False avg sgd categorical_crossentropy\n",
      "False False avg sgd sparse_categorical_crossentropy\n",
      "False False avg sgd binary_crossentropy\n",
      "False False avg adam mean_squared_error\n",
      "False False avg adam categorical_crossentropy\n",
      "False False avg adam sparse_categorical_crossentropy\n",
      "False False avg adam binary_crossentropy\n",
      "False False avg adadelta mean_squared_error\n",
      "False False avg adadelta categorical_crossentropy\n",
      "False False avg adadelta sparse_categorical_crossentropy\n",
      "False False avg adadelta binary_crossentropy\n",
      "False False max sgd mean_squared_error\n",
      "False False max sgd categorical_crossentropy\n",
      "False False max sgd sparse_categorical_crossentropy\n",
      "False False max sgd binary_crossentropy\n",
      "False False max adam mean_squared_error\n",
      "False False max adam categorical_crossentropy\n",
      "False False max adam sparse_categorical_crossentropy\n",
      "False False max adam binary_crossentropy\n",
      "False False max adadelta mean_squared_error\n",
      "False False max adadelta categorical_crossentropy\n",
      "False False max adadelta sparse_categorical_crossentropy\n",
      "False False max adadelta binary_crossentropy\n",
      "False True avg sgd mean_squared_error\n",
      "False True avg sgd categorical_crossentropy\n",
      "False True avg sgd sparse_categorical_crossentropy\n",
      "False True avg sgd binary_crossentropy\n",
      "False True avg adam mean_squared_error\n",
      "False True avg adam categorical_crossentropy\n",
      "False True avg adam sparse_categorical_crossentropy\n",
      "False True avg adam binary_crossentropy\n",
      "False True avg adadelta mean_squared_error\n",
      "False True avg adadelta categorical_crossentropy\n",
      "False True avg adadelta sparse_categorical_crossentropy\n",
      "False True avg adadelta binary_crossentropy\n",
      "False True max sgd mean_squared_error\n",
      "False True max sgd categorical_crossentropy\n",
      "False True max sgd sparse_categorical_crossentropy\n",
      "False True max sgd binary_crossentropy\n",
      "False True max adam mean_squared_error\n",
      "False True max adam categorical_crossentropy\n",
      "False True max adam sparse_categorical_crossentropy\n",
      "False True max adam binary_crossentropy\n",
      "False True max adadelta mean_squared_error\n",
      "False True max adadelta categorical_crossentropy\n",
      "False True max adadelta sparse_categorical_crossentropy\n",
      "False True max adadelta binary_crossentropy\n",
      "True False avg sgd mean_squared_error\n",
      "True False avg sgd categorical_crossentropy\n",
      "True False avg sgd sparse_categorical_crossentropy\n",
      "True False avg sgd binary_crossentropy\n",
      "True False avg adam mean_squared_error\n",
      "True False avg adam categorical_crossentropy\n",
      "True False avg adam sparse_categorical_crossentropy\n",
      "True False avg adam binary_crossentropy\n",
      "True False avg adadelta mean_squared_error\n",
      "True False avg adadelta categorical_crossentropy\n",
      "True False avg adadelta sparse_categorical_crossentropy\n",
      "True False avg adadelta binary_crossentropy\n",
      "True False max sgd mean_squared_error\n",
      "True False max sgd categorical_crossentropy\n",
      "True False max sgd sparse_categorical_crossentropy\n",
      "True False max sgd binary_crossentropy\n",
      "True False max adam mean_squared_error\n",
      "True False max adam categorical_crossentropy\n",
      "True False max adam sparse_categorical_crossentropy\n",
      "True False max adam binary_crossentropy\n",
      "True False max adadelta mean_squared_error\n",
      "True False max adadelta categorical_crossentropy\n",
      "True False max adadelta sparse_categorical_crossentropy\n",
      "True False max adadelta binary_crossentropy\n",
      "True True avg sgd mean_squared_error\n",
      "True True avg sgd categorical_crossentropy\n",
      "True True avg sgd sparse_categorical_crossentropy\n",
      "True True avg sgd binary_crossentropy\n",
      "True True avg adam mean_squared_error\n",
      "True True avg adam categorical_crossentropy\n",
      "True True avg adam sparse_categorical_crossentropy\n",
      "True True avg adam binary_crossentropy\n",
      "True True avg adadelta mean_squared_error\n",
      "True True avg adadelta categorical_crossentropy\n",
      "True True avg adadelta sparse_categorical_crossentropy\n",
      "True True avg adadelta binary_crossentropy\n",
      "True True max sgd mean_squared_error\n",
      "True True max sgd categorical_crossentropy\n",
      "True True max sgd sparse_categorical_crossentropy\n",
      "True True max sgd binary_crossentropy\n",
      "True True max adam mean_squared_error\n",
      "True True max adam categorical_crossentropy\n",
      "True True max adam sparse_categorical_crossentropy\n",
      "True True max adam binary_crossentropy\n",
      "True True max adadelta mean_squared_error\n",
      "True True max adadelta categorical_crossentropy\n",
      "True True max adadelta sparse_categorical_crossentropy\n",
      "True True max adadelta binary_crossentropy\n"
     ]
    }
   ],
   "source": [
    "# Waaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaat\n",
    "\n",
    "for t in TOP:\n",
    "    for d in DATA_GEN:\n",
    "        for p in RESNET50_POOLING:\n",
    "            for o in OPTIMIZER:\n",
    "                for l in OBJECTIVE_FUNCTION:\n",
    "                    exper1(top=t, pool=p, opt=o, loss=l, dataGen=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
