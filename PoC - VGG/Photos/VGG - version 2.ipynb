{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprawdzanie środowiska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przygotowanie odpowiednich danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dla PoC wykonuje obliczenia dla:\n",
    " * '../../data/DogsCats'\n",
    "Folder docelowy:\n",
    " * '../../data/Photos'\n",
    "Folder Casia:\n",
    " * '../../data/Casia'\n",
    "'''\n",
    "\n",
    "dir_path = '../../data/Photos'\n",
    "A_folder = 'originals'\n",
    "B_folder = 'photoshops'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Załadowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "# fix random bo tak ( ͡° ͜ʖ ͡°)\n",
    "odp = 42\n",
    "numpy.random.seed(odp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stałe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wilkości odpowiednie dla ResNetu\n",
    "\n",
    "IMAGE_WIDTH=150\n",
    "IMAGE_HEIGHT=150\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przygotowanie Danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Opis danych:\n",
    "1 - klasa 1 -> Originals\n",
    "0 - klasa 2 -> Photoshops\n",
    "''' \n",
    "\n",
    "A_folder_list = os.listdir(dir_path + '/' + A_folder)\n",
    "B_folder_list = os.listdir(dir_path + '/' + B_folder)\n",
    "\n",
    "filenames = []\n",
    "categories = []\n",
    "\n",
    "for filename in A_folder_list:\n",
    "    categories.append(1)\n",
    "    filenames.append(dir_path + '/' + A_folder + '/' + filename)\n",
    "\n",
    "for filename in B_folder_list:\n",
    "    categories.append(0)\n",
    "    filenames.append(dir_path + '/' + B_folder + '/' + filename)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mieszamy!\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.choice(df['filename'])\n",
    "image = load_img(sample)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "\n",
    "def ft_ela(image_path):\n",
    "    im = Image.open(image_path).convert('RGB')\n",
    "    im.save('tmp.jpg', 'JPEG', quality=95)\n",
    "    resaved_im = Image.open('tmp.jpg')\n",
    "\n",
    "    ela_im = ImageChops.difference(im, resaved_im)\n",
    "\n",
    "    extrema = ela_im.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    if max_diff == 0:\n",
    "        max_diff = 1\n",
    "    scale = 255.0 / max_diff\n",
    "    \n",
    "    ela_im = ImageEnhance.Brightness(ela_im).enhance(scale)\n",
    "    ela_im = ela_im.resize(IMAGE_SIZE)\n",
    "    ret = numpy.array(ela_im).flatten() / 255\n",
    "\n",
    "    return ret, ela_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ela = ft_ela(sample)\n",
    "\n",
    "plt.imshow(ela[1])\n",
    "print(f'Kształt: {ela[0].shape}')\n",
    "print(f'Max: {numpy.amax(ela[0])}')\n",
    "print(f'Min: {numpy.amin(ela[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przeliczenie Cech Zdjęć + Kategorii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " '''\n",
    "Podział danych z całego df na X i y:\n",
    "\n",
    "X - wszystko oprócz category\n",
    "y - category\n",
    "'''\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    X.append(numpy.array(ft_ela(row[0])[0]))\n",
    "    Y.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.array(X)\n",
    "Y = numpy.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zapis/Odczyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save(features, labels, dataframe, name):\n",
    "    h5f_data = h5py.File('data_' + str(name) + '.h5', 'w')\n",
    "    h5f_data.create_dataset('dataset', data=numpy.array(features))\n",
    "\n",
    "    h5f_label = h5py.File('labels_' + str(name) + '.h5', 'w')\n",
    "    h5f_label.create_dataset('dataset', data=numpy.array(labels))\n",
    "\n",
    "    h5f_data.close()\n",
    "    h5f_label.close()\n",
    "\n",
    "    dataframe.to_csv('dataframe_' + str(name) + '.csv')\n",
    "    \n",
    "def load(features, labels, dataframe):\n",
    "    h5f_data  = h5py.File(features, 'r')\n",
    "    h5f_label = h5py.File(labels, 'r')\n",
    "\n",
    "    global_features_string = h5f_data['dataset']\n",
    "    global_labels_string   = h5f_label['dataset']\n",
    "\n",
    "    global_features = numpy.array(global_features_string)\n",
    "    global_labels   = numpy.array(global_labels_string)\n",
    "\n",
    "    h5f_data.close()\n",
    "    h5f_label.close()\n",
    "    \n",
    "    df = pd.read_csv(dataframe, index_col = 0)  \n",
    "    \n",
    "    return global_features, global_labels, df\n",
    "    \n",
    "save(X, Y, df, name='Casia_CNN')\n",
    "\n",
    "X, Y, df = load('data_Casia_CNN.h5', 'labels_Casia_CNN.h5', 'dataframe_Casia_CNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Kształt po wczytaniu:')\n",
    "print(f'\\t X: {X.shape}')\n",
    "print(f'\\t Y: {Y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funkcję liczące statystyki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import load_model, clone_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countStats(_y_true, _y_pred):\n",
    "    accuracy = accuracy_score(_y_true, _y_pred, normalize=True)\n",
    "    precision = precision_score(_y_true, _y_pred, average='binary')\n",
    "    recall = recall_score(_y_true, _y_pred, average='binary')\n",
    "    fscore = f1_score(_y_true, _y_pred, average='binary')\n",
    "    \n",
    "    return accuracy, precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Źrodło:\n",
    "https://medium.com/@aakashgoel12/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
    "'''\n",
    "\n",
    "def get_f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    \n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "def plot_cm(cm, classes):\n",
    "    fig = plot_confusion_matrix(conf_mat=cm,\n",
    "                          colorbar=True, \n",
    "                          show_absolute=True,\n",
    "                          show_normed=True,\n",
    "                          class_names=classes,\n",
    "                          figsize=(10, 8))\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cb_early_stopper - skończenie uczenia kiedy val_loss nie będzie się poprawiać przez 10 epok\n",
    "cb_checkpointer - zapis modelu do pliku 'best.h5' modeli o najlepszym(najmniejszym) val_loss\n",
    "cb_learning_rate_reduction - zmniejszenie LR jeśli val_loss nie będzie się poprawiać przez 5 epok\n",
    "'''\n",
    "\n",
    "EARLY_STOP_PATIENCE = 10\n",
    "LEARNING_RATE_PATIENCE = 5\n",
    "\n",
    "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE, verbose=0)\n",
    "cb_checkpointer = ModelCheckpoint(filepath = 'best.h5', monitor = 'val_loss', save_best_only = True, verbose=0)\n",
    "cb_learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=LEARNING_RATE_PATIENCE, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dobór parametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "activation = 'relu'\n",
    "loss_type = 'binary_crossentropy'\n",
    "optimizer = RMSprop(lr=1e-5)\n",
    "dropout = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from keras.applications import VGG16\n",
    "\n",
    "# Model\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
    "\n",
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(512, activation=activation))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss_type, optimizer=optimizer, metrics=['accuracy', get_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"base_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "features = X\n",
    "labels = Y\n",
    "name = 'CNN'\n",
    "\n",
    "\n",
    "tcm_list = []\n",
    "tAccuracy_list = []\n",
    "tPrecision_list = []\n",
    "tRecall_list = []\n",
    "tFScore_list = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=odp)\n",
    "    \n",
    "scores_a = numpy.zeros((1, 5))\n",
    "scores_p = numpy.zeros((1, 5))\n",
    "scores_r = numpy.zeros((1, 5))\n",
    "scores_f = numpy.zeros((1, 5))\n",
    "\n",
    "for fold_id, (train_index, test_index) in enumerate(kf.split(features, labels)):\n",
    "    X_train = features[train_index].reshape(-1, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
    "    Y_train = labels[train_index]\n",
    "    \n",
    "    X_test = features[test_index].reshape(-1, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
    "    Y_test = labels[test_index]\n",
    "    \n",
    "    EARLY_STOP_PATIENCE = 10\n",
    "    LEARNING_RATE_PATIENCE = 5\n",
    "\n",
    "    cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE, verbose=0)\n",
    "    cb_checkpointer = ModelCheckpoint(filepath = 'best.h5', monitor = 'val_loss', save_best_only = True, verbose=0)\n",
    "    cb_learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=LEARNING_RATE_PATIENCE, verbose=0)\n",
    "    \n",
    "    clf = load_model('base_model.h5', custom_objects={'get_f1': get_f1})\n",
    "    history = clf.fit(\n",
    "        x = X_train,\n",
    "        y = Y_train,\n",
    "        batch_size = batch_size,\n",
    "        epochs = epochs,\n",
    "        validation_data = (X_test, Y_test),\n",
    "        callbacks = [cb_checkpointer, cb_early_stopper, cb_learning_rate_reduction],\n",
    "        verbose = 0\n",
    "    )\n",
    "    \n",
    "    clf.load_weights('best.h5')\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    y_pred = numpy.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "    accuracy, precision, recall, fscore = countStats(Y_test, y_pred)\n",
    "    cm = confusion_matrix(Y_test, y_pred)\n",
    "    scores_a[0, fold_id] = accuracy\n",
    "    scores_p[0, fold_id] = precision\n",
    "    scores_r[0, fold_id] = recall\n",
    "    scores_f[0, fold_id] = fscore\n",
    "\n",
    "    tAccuracy_list.append(accuracy)\n",
    "    tPrecision_list.append(precision)\n",
    "    tRecall_list.append(recall)\n",
    "    tFScore_list.append(fscore)\n",
    "    tcm_list.append(cm)\n",
    "    \n",
    "    print(f'[{fold_id + 1} done!]', end='')\n",
    "\n",
    "printmd(f'# {name}:')\n",
    "print(f'\\n\\nKształt danych:')\n",
    "print(f'\\t X_train: {X_train.shape}')\n",
    "print(f'\\t X_test: {X_test.shape}')\n",
    "print(f'\\t y_train: {Y_train.shape}')\n",
    "print(f'\\t y_test: {Y_test.shape}')\n",
    "    \n",
    "accuracy_m = numpy.mean(tAccuracy_list)\n",
    "precision_m = numpy.mean(tPrecision_list)\n",
    "recall_m = numpy.mean(tRecall_list)\n",
    "fscore_m = numpy.mean(tFScore_list)\n",
    "        \n",
    "accuracy_std = numpy.std(tAccuracy_list)\n",
    "precision_std = numpy.std(tPrecision_list)\n",
    "recall_std = numpy.std(tRecall_list)\n",
    "fscore_std = numpy.std(tFScore_list)\n",
    "    \n",
    "cm = sum(tcm_list)\n",
    "\n",
    "results = [['CNN', \n",
    "            f'{accuracy_m:.3f} ({accuracy_std:.2f})',\n",
    "            f'{precision_m:.3f} ({precision_std:.2f})',\n",
    "            f'{recall_m:.3f} ({recall_std:.2f})',\n",
    "            f'{fscore_m:.3f} ({fscore_std:.2f})',\n",
    "            f'{cm}']]\n",
    "                            \n",
    "printmd(f'### Rezultaty:')\n",
    "headers = [\"Kernel\", \"Accuracy\", \"Precision\", \"Recall\", \"Fscore\", \"CM\"]\n",
    "print('\\n')\n",
    "print(tabulate(results, headers=headers))\n",
    "                            \n",
    "with open(f'{name}_result.txt', 'w') as f:\n",
    "    print(tabulate(results, headers=headers), file=f)\n",
    "                            \n",
    "numpy.save(f'{name}_results_a', scores_a)\n",
    "numpy.save(f'{name}_results_p', scores_p)\n",
    "numpy.save(f'{name}_results_r', scores_r)\n",
    "numpy.save(f'{name}_results_f', scores_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie najlepszego\n",
    "model.load_weights('best.h5')\n",
    "\n",
    "# Zapis\n",
    "model.save('the_best.h5')\n",
    "\n",
    "# Zapis History\n",
    "numpy.save('history.npy', history.history)\n",
    "# history = numpy.load('history.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statystyki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 15))\n",
    "\n",
    "# Wykres loss\n",
    "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(history.history['val_loss'], color='r', label=\"Validation loss\")\n",
    "ax1.set_ylim([-0.1, 1.1])\n",
    "ax1.legend(loc='best', shadow=True)\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "\n",
    "# Wykres accuracy\n",
    "ax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_ylim([-0.1, 1.1])\n",
    "ax2.legend(loc='best', shadow=True)\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax2.set_xlabel('epoch')\n",
    "\n",
    "# Wykres F1\n",
    "ax3.plot(history.history['get_f1'], color='b', label=\"Training f1\")\n",
    "ax3.plot(history.history['val_get_f1'], color='r',label=\"Validation f1\")\n",
    "ax3.set_ylim([-0.1, 1.1])\n",
    "ax3.legend(loc='best', shadow=True)\n",
    "ax3.set_ylabel('f1')\n",
    "ax3.set_xlabel('epoch')\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('history.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_cm(cm, ['Originals', 'Photoshops'])\n",
    "fig[0].savefig('cm.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
