{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cel\n",
    "\n",
    " * Poprzedni eksperyment - Nasze dane balanced data\n",
    " * Inbalanced data\n",
    " * UnderSampling\n",
    " * OverSampling\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports + DataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "slash = '/' if os.name != 'nt' else '\\\\'\n",
    "dataSource = '/home/torak28/Desktop/Studia/MGU/Projekt/dataSource' if os.name != 'nt' else 'D:\\Studia\\MGU\\Data\\PS-Battles-master'\n",
    "path = dataSource\n",
    "os.chdir(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def verify_picture(pic):\n",
    "    try:\n",
    "        im = Image.open(pic)\n",
    "        im.verify()\n",
    "        im.close()\n",
    "        im = Image.open(pic)\n",
    "        im.resize((224,224))\n",
    "        im.convert('RGB')\n",
    "        if sum(im.convert(\"L\").getextrema()) in (0, 2):\n",
    "            return False\n",
    "        if os.stat(pic).st_size == 503:\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as err: \n",
    "        return False\n",
    "\n",
    "if os.name != 'nt': \n",
    "    out = verify_picture('../../MGU/Projekt/PS-Battles-master/originals/49366m.jpg')\n",
    "    print(out)\n",
    "else:\n",
    "    out = verify_picture('..\\..\\MGU\\Data\\PS-Battles-master\\originals\\49366m.jpg')\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "\n",
    "def clear():\n",
    "    clearPath = '/home/torak28/Desktop/Studia/MGU/Projekt/photos' if os.name != 'nt' else 'D:\\Studia\\MGU\\Data\\photos'\n",
    "\n",
    "    tmp = ['balanced', 'inbl', 'Oversampling', 'Undersampling']\n",
    "    tmp2 = ['test', 'valid']\n",
    "    tmp3 = ['org', 'ps']\n",
    "\n",
    "    slash = '/' if os.name != 'nt' else '\\\\'\n",
    "\n",
    "    for i in tmp:\n",
    "        for j in tmp2:\n",
    "            for k in tmp3:\n",
    "                rm = clearPath + slash + i + slash + j + slash + k + slash\n",
    "                rmtree(rm)\n",
    "                os.mkdir(rm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def stats():\n",
    "    tmp = ['balanced', 'inbl', 'Oversampling', 'Undersampling']\n",
    "    statPath = '/home/torak28/Desktop/Studia/MGU/Projekt/photos' if os.name != 'nt' else 'D:\\Studia\\MGU\\Data\\photos'\n",
    "    statPath = statPath + slash\n",
    "    \n",
    "    for i in tmp:\n",
    "\n",
    "        plt.figure(1, figsize = (15,8)) \n",
    "        plt.suptitle(i, fontsize=16)\n",
    "        \n",
    "        # Before\n",
    "        plt.subplot(231)  \n",
    "\n",
    "        org_files = len(os.listdir(dataSource + slash + 'originals' + slash))\n",
    "        ps_files = 0\n",
    "        for j in os.listdir(dataSource + slash + 'photoshops' + slash):\n",
    "            ps_files += len(os.listdir(dataSource + slash + 'photoshops' + slash + j))  \n",
    "        plt.bar(['org', 'ps'], [org_files, ps_files], align='center', alpha=0.5)  \n",
    "\n",
    "        plt.title('Org Data')  \n",
    "        plt.ylabel('Number of Files') \n",
    "    \n",
    "        # Testing\n",
    "        plt.subplot(232)  \n",
    "\n",
    "        org_files = len(os.listdir(statPath + i + slash + 'test' + slash + 'org' + slash))\n",
    "        ps_files = len(os.listdir(statPath + i + slash  + 'test' + slash + 'ps' + slash))  \n",
    "        lim = org_files if org_files >= ps_files else ps_files\n",
    "        plt.bar(['org', 'ps'], [org_files, ps_files], align='center', alpha=0.5)  \n",
    "\n",
    "        plt.title('Test')  \n",
    "        plt.ylabel('Number of Files') \n",
    "\n",
    "        # Valid\n",
    "        plt.subplot(233)  \n",
    "\n",
    "        org_files = len(os.listdir(statPath + i + slash  + 'valid' + slash + 'org' + slash))\n",
    "        ps_files = len(os.listdir(statPath + i + slash  + 'valid' + slash + 'ps' + slash))  \n",
    "        plt.bar(['org', 'ps'], [org_files, ps_files], align='center', alpha=0.5)  \n",
    "\n",
    "        plt.title('Valid')  \n",
    "        plt.ylabel('Number of Files')  \n",
    "        plt.ylim((0, lim)) \n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced Data(take first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programs\\python37\\lib\\site-packages\\PIL\\Image.py:989: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files: 21896\n",
      "\tORG: 10948\n",
      "\tPSS: 10948\n",
      "Test data: 21896, Valid data: 5474\n"
     ]
    }
   ],
   "source": [
    "def do_it_test(dst):\n",
    "\n",
    "    org = os.listdir('originals')\n",
    "    for i in org:\n",
    "        if verify_picture('originals' + slash + i):\n",
    "            name = os.path.splitext(i)[0]\n",
    "            tmp = os.listdir('photoshops' + slash + name)[:1]\n",
    "            for j in tmp:\n",
    "                if verify_picture('photoshops' + slash + name + slash + j):\n",
    "                    copyfile(os.path.abspath('photoshops' + slash + name + slash + j), os.path.abspath(dst + 'test' + slash + 'ps' + slash + j))\n",
    "                    copyfile(os.path.abspath('originals' + slash + i), os.path.abspath(dst + 'test' + slash + 'org' + slash + i))\n",
    "    all_files = len(os.listdir(dst + 'test' + slash + 'org' + slash)) + len(os.listdir(dst + 'test' + slash + 'ps' + slash))\n",
    "    org_files = len(os.listdir(dst + 'test' + slash + 'org' + slash))\n",
    "    ps_files = len(os.listdir(dst + 'test' + slash + 'ps' + slash))         \n",
    "    print(f'All files: {all_files}\\n\\tORG: {org_files}\\n\\tPSS: {ps_files}')\n",
    "\n",
    "import random\n",
    "\n",
    "def do_it_valid(dst='..' + slash + 'photos' + slash + 'balanced' + slash):\n",
    "    amount_of_org = round(len(os.listdir(dst + 'test' + slash + 'org' + slash)) / 4)\n",
    "    amount_of_ps = round(len(os.listdir(dst + 'test' + slash + 'ps' + slash)) / 4)\n",
    "    \n",
    "    org = os.listdir(dst + 'test' + slash + 'org' + slash)\n",
    "    ps = os.listdir(dst + 'test' + slash + 'ps' + slash)\n",
    "    \n",
    "\n",
    "    for _ in random.sample(org, k=amount_of_org):\n",
    "        copyfile(os.path.abspath(dst + 'test' + slash + 'org' + slash + _), dst + 'valid' + slash + 'org' + slash + _)\n",
    "\n",
    "    for _ in random.sample(ps, k=amount_of_ps):\n",
    "        copyfile(os.path.abspath(dst + 'test' + slash + 'ps' + slash + _), dst + 'valid' + slash + 'ps' + slash + _)\n",
    "\n",
    "    test = len(os.listdir(dst + 'test' + slash + 'org' + slash)) + len(os.listdir(dst + 'test' + slash + 'ps' + slash))\n",
    "    valid = len(os.listdir(dst + 'valid' + slash + 'org' + slash)) + len(os.listdir(dst + 'valid' + slash + 'ps' + slash))\n",
    "\n",
    "    print(f'Test data: {test}, Valid data: {valid}')\n",
    "\n",
    "do_it_test(dst='..' + slash + 'photos' + slash + 'balanced' + slash)\n",
    "do_it_valid(dst='..' + slash + 'photos' + slash + 'balanced' + slash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files: 98113\n",
      "\tORG: 11122\n",
      "\tPSS: 86991\n",
      "Test data: 98113, Valid data: 24528\n"
     ]
    }
   ],
   "source": [
    "def do_it_test(dst):\n",
    "\n",
    "    org = os.listdir('originals')\n",
    "    for i in org:\n",
    "        if verify_picture('originals' + slash + i):\n",
    "            name = os.path.splitext(i)[0]\n",
    "            tmp = os.listdir('photoshops' + slash + name)\n",
    "            for j in tmp:\n",
    "                if verify_picture('photoshops' + slash + name + slash + j):\n",
    "                    copyfile(os.path.abspath('photoshops' + slash + name + slash + j), os.path.abspath(dst + 'test' + slash + 'ps' + slash + j))\n",
    "        copyfile(os.path.abspath('originals' + slash + i), os.path.abspath(dst + 'test' + slash + 'org' + slash + i))\n",
    "    all_files = len(os.listdir(dst + 'test' + slash + 'org' + slash)) + len(os.listdir(dst + 'test' + slash + 'ps' + slash))\n",
    "    org_files = len(os.listdir(dst + 'test' + slash + 'org' + slash))\n",
    "    ps_files = len(os.listdir(dst + 'test' + slash + 'ps' + slash))         \n",
    "    print(f'All files: {all_files}\\n\\tORG: {org_files}\\n\\tPSS: {ps_files}')\n",
    "    \n",
    "do_it_test(dst='..' + slash + 'photos' + slash + 'inbl' + slash)\n",
    "do_it_valid(dst='..' + slash + 'photos' + slash + 'inbl' + slash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files: 21896\n",
      "\tORG: 10948\n",
      "\tPSS: 10948\n",
      "Test data: 21896, Valid data: 5474\n"
     ]
    }
   ],
   "source": [
    "def do_it_test(dst):\n",
    "\n",
    "    org = os.listdir('originals')\n",
    "    for i in org:\n",
    "        if verify_picture('originals' + slash + i):\n",
    "            name = os.path.splitext(i)[0]\n",
    "            tmp = [random.choice(os.listdir('photoshops' + slash + name))]\n",
    "            for j in tmp:\n",
    "                if verify_picture('photoshops' + slash + name + slash + j):\n",
    "                    copyfile(os.path.abspath('photoshops' + slash + name + slash + j), os.path.abspath(dst + 'test' + slash + 'ps' + slash + j))\n",
    "                    copyfile(os.path.abspath('originals' + slash + i), os.path.abspath(dst + 'test' + slash + 'org' + slash + i))\n",
    "    all_files = len(os.listdir(dst + 'test' + slash + 'org' + slash)) + len(os.listdir(dst + 'test' + slash + 'ps' + slash))\n",
    "    org_files = len(os.listdir(dst + 'test' + slash + 'org' + slash))\n",
    "    ps_files = len(os.listdir(dst + 'test' + slash + 'ps' + slash))         \n",
    "    print(f'All files: {all_files}\\n\\tORG: {org_files}\\n\\tPSS: {ps_files}')\n",
    "\n",
    "do_it_test(dst='..' + slash + 'photos' + slash + 'Undersampling' + slash)\n",
    "do_it_valid(dst='..' + slash + 'photos' + slash + 'Undersampling' + slash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9819172a17f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'All files: {all_files}\\n\\tORG: {org_files}\\n\\tPSS: {ps_files}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mdo_it_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'..'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mslash\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'photos'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mslash\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Oversampling'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mslash\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[0mdo_it_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'..'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mslash\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'photos'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mslash\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Oversampling'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mslash\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-9819172a17f6>\u001b[0m in \u001b[0;36mdo_it_test\u001b[1;34m(dst)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mimageGen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_to_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdst\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'test'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mslash\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'org'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mxd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimageGen\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0mxd\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mxd\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python37\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python37\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# The transformation of images is not under thread lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# so it can be done in parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python37\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             x = self.image_data_generator.apply_transform(\n\u001b[1;32m--> 153\u001b[1;33m                 x.astype(self.dtype), params)\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python37\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py\u001b[0m in \u001b[0;36mapply_transform\u001b[1;34m(self, x, transform_parameters)\u001b[0m\n\u001b[0;32m    868\u001b[0m                                    \u001b[0mfill_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m                                    \u001b[0mcval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m                                    order=self.interpolation_order)\n\u001b[0m\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransform_parameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'channel_shift_intensity'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python37\\lib\\site-packages\\keras_preprocessing\\image\\affine_transformations.py\u001b[0m in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[0;32m    331\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m             cval=cval) for x_channel in x]\n\u001b[0m\u001b[0;32m    334\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_axis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python37\\lib\\site-packages\\keras_preprocessing\\image\\affine_transformations.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    331\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m             cval=cval) for x_channel in x]\n\u001b[0m\u001b[0;32m    334\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_axis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python37\\lib\\site-packages\\scipy\\ndimage\\interpolation.py\u001b[0m in \u001b[0;36maffine_transform\u001b[1;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         _nd_image.geometric_transform(filtered, None, None, matrix, offset,\n\u001b[1;32m--> 486\u001b[1;33m                                       output, order, mode, cval, None, None)\n\u001b[0m\u001b[0;32m    487\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from numpy import expand_dims\n",
    "\n",
    "def do_it_inbl(dst):\n",
    "    ver_org = []\n",
    "    org = os.listdir('originals')\n",
    "    for i in org:\n",
    "        if verify_picture('originals' + slash + i):\n",
    "            ver_org.append(i)\n",
    "            name = os.path.splitext(i)[0]\n",
    "            tmp = os.listdir('photoshops' + slash + name)\n",
    "            for j in tmp:\n",
    "                if verify_picture('photoshops' + slash + name + slash + j):\n",
    "                    copyfile(os.path.abspath('photoshops' + slash + name + slash + j), os.path.abspath(dst + 'test' + slash + 'ps' + slash + j))\n",
    "        copyfile(os.path.abspath('originals' + slash + i), os.path.abspath(dst + 'test' + slash + 'org' + slash + i))\n",
    "    return ver_org\n",
    "        \n",
    "def do_it_test(dst):\n",
    "    \n",
    "    org = do_it_inbl(dst)\n",
    "    diff = len(os.listdir(dst + 'test' + slash + 'ps' + slash)) - len(os.listdir(dst + 'test' + slash + 'org' + slash))\n",
    "    imgs = random.sample(org, diff)\n",
    "    datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        brightness_range=[0.2,1.0],\n",
    "        zoom_range=[0.5,1.0]\n",
    "    )\n",
    "    tmp = []\n",
    "    for img in imgs:\n",
    "        img = load_img(os.path.abspath('originals' + slash + img))\n",
    "        img = img_to_array(img)\n",
    "        img = expand_dims(img, 0)\n",
    "        tmp.append(img)\n",
    "    imageGen = datagen.flow(tmp, batch_size=1, save_to_dir=dst + 'test' + slash + 'org',save_prefix=\"image\", save_format=\"jpg\")\n",
    "    xd = 0\n",
    "    for image in imageGen:\n",
    "        xd += 1\n",
    "        if xd == len(tmp):\n",
    "            break    \n",
    "    all_files = len(os.listdir(dst + 'test' + slash + 'org' + slash)) + len(os.listdir(dst + 'test' + slash + 'ps' + slash))\n",
    "    org_files = len(os.listdir(dst + 'test' + slash + 'org' + slash))\n",
    "    ps_files = len(os.listdir(dst + 'test' + slash + 'ps' + slash))         \n",
    "    print(f'All files: {all_files}\\n\\tORG: {org_files}\\n\\tPSS: {ps_files}')\n",
    "\n",
    "do_it_test(dst='..' + slash + 'photos' + slash + 'Oversampling' + slash)\n",
    "do_it_valid(dst='..' + slash + 'photos' + slash + 'Oversampling' + slash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear()\n",
    "\n",
    "clearPath = '/home/torak28/Desktop/Studia/MGU/Projekt/photos' if os.name != 'nt' else 'D:\\Studia\\MGU\\Data\\photos'\n",
    "\n",
    "tmp = ['Oversampling']\n",
    "tmp2 = ['test', 'valid']\n",
    "tmp3 = ['org', 'ps']\n",
    "\n",
    "slash = '/' if os.name != 'nt' else '\\\\'\n",
    "\n",
    "for i in tmp:\n",
    "    for j in tmp2:\n",
    "        for k in tmp3:\n",
    "            rm = clearPath + slash + i + slash + j + slash + k + slash\n",
    "            rmtree(rm)\n",
    "            os.mkdir(rm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exper1(top, pool, opt, loss, dataGen, pathFile):\n",
    "    out = []\n",
    "    print(f'MODEL with:')\n",
    "    print(f'\\tinclude_top: {top}')\n",
    "    print(f'\\tpooling: {pool}')\n",
    "    print(f'\\toptimizer: {opt}')\n",
    "    print(f'\\tloss_func: {loss}')\n",
    "    print(f'\\tdata_gen: {dataGen}')\n",
    "    \n",
    "    # Model\n",
    "    model = Sequential()\n",
    "    model.add(ResNet50(include_top = top, pooling = pool, weights = 'imagenet'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
    "    model.layers[0].trainable = False\n",
    "    model.summary()\n",
    "    model.compile(optimizer = opt, loss = loss, metrics = LOSS_METRICS)\n",
    "    \n",
    "    # Data Gen\n",
    "    image_size = IMAGE_RESIZE\n",
    "    if dataGen:\n",
    "        data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    else:\n",
    "        data_generator = ImageDataGenerator(\n",
    "            shear_range=10,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            preprocessing_function=preprocess_input\n",
    "        )\n",
    "    \n",
    "    # Data\n",
    "    path = pathFile\n",
    "    slash = '\\\\'\n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        directory=path + slash + 'test' + slash,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_TRAINING,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = data_generator.flow_from_directory(\n",
    "        directory=path + slash + 'valid'+ slash,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_VALIDATION,\n",
    "        class_mode='categorical') \n",
    "    \n",
    "    # Callbacks\n",
    "    cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n",
    "    cb_checkpointer = ModelCheckpoint(filepath = '..' + slash + 'working' + slash + 'best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')\n",
    "    \n",
    "    # Fit\n",
    "    fit_history = model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "        callbacks=[cb_checkpointer, cb_early_stopper]\n",
    "    )\n",
    "    model.load_weights('..' + slash + 'working' + slash + 'best.hdf5')\n",
    "    name = 'DogsCats_Top_' + str(top) + '_Pool_' + pool + '_Opt_' + opt + '_Loss_' + loss + '_dataGen_' + str(dataGen)\n",
    "    model.save('..' + slash + 'working' + slash + name + '.h5')\n",
    "    \n",
    "    # Score v1\n",
    "    scoreRes = model.evaluate_generator(\n",
    "        generator=validation_generator\n",
    "    )\n",
    "    print(f'Accuracy = {scoreRes}')\n",
    "    tmp = {}\n",
    "    tmp[name] = scoreRes\n",
    "    out.append(tmp)\n",
    "    \n",
    "    # Score v2\n",
    "    plt.figure(1, figsize = (15,8)) \n",
    "    plt.subplot(221)  \n",
    "    plt.plot(fit_history.history['accuracy'])  \n",
    "    plt.plot(fit_history.history['val_accuracy'])  \n",
    "    plt.title('model accuracy')  \n",
    "    plt.ylabel('accuracy')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'valid']) \n",
    "    plt.subplot(222)  \n",
    "    plt.plot(fit_history.history['loss'])  \n",
    "    plt.plot(fit_history.history['val_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'valid']) \n",
    "    plt.show()\n",
    "    \n",
    "    # Show some predictions\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        directory = path + slash + 'show' + slash,\n",
    "        target_size = (image_size, image_size),\n",
    "        batch_size = BATCH_SIZE_TESTING,\n",
    "        class_mode = None,\n",
    "        shuffle = False,\n",
    "        seed = 123\n",
    "    )\n",
    "    test_generator.reset()\n",
    "    pred = model.predict_generator(test_generator, steps = len(test_generator), verbose = 1)\n",
    "    predicted_class_indices = np.argmax(pred, axis = 1)\n",
    "    TEST_DIR = path + slash + 'show' + slash\n",
    "    f, ax = plt.subplots(5, 5, figsize = (15, 15))\n",
    "    for i in range(0,25):\n",
    "        imgBGR = cv2.imread(TEST_DIR + test_generator.filenames[i])\n",
    "        imgRGB = cv2.cvtColor(imgBGR, cv2.COLOR_BGR2RGB)\n",
    "        # a if condition else b\n",
    "        predicted_class = \"Dog\" if predicted_class_indices[i] else \"Cat\"\n",
    "        ax[i//5, i%5].imshow(imgRGB)\n",
    "        ax[i//5, i%5].axis('off')\n",
    "        ax[i//5, i%5].set_title(\"Predicted:{}\".format(predicted_class))    \n",
    "    plt.show()\n",
    "    \n",
    "    # End\n",
    "    print('---KONIEC---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Var + exp2 func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\\\Studia\\\\MGU\\\\Data\\\\photos'\n",
    "\n",
    "slash = '/' if os.name != 'nt' else '\\\\'\n",
    "\n",
    "folders = ['balanced', 'inbl', 'Oversampling', 'Undersampling']\n",
    "\n",
    "def exp2(pth):\n",
    "    exper1(False, 'avg', 'sgd', 'categorical_crossentropy', True, pth)\n",
    "#     exper1(False, 'avg', 'sgd', 'mean_squared_error', True, pth)\n",
    "#     exper1(False, 'avg', 'adam', 'mean_squared_error', True, pth)\n",
    "#     exper1(False, 'avg', 'adam', 'categorical_crossentropy', True, pth)\n",
    "#     exper1(False, 'avg', 'adadelta', 'categorical_crossentropy', True, pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    pathFile = path + slash + folder\n",
    "    exp2(pth=pathFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
