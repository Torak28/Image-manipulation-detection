{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cel\n",
    "\n",
    " * Poprzedni eksperyment - Nasze dane balanced data\n",
    " * Inbalanced data\n",
    " * UnderSampling\n",
    " * OverSampling\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports + DataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "slash = '/' if os.name != 'nt' else '\\\\'\n",
    "dataSource = '/home/torak28/Desktop/Studia/MGU/Projekt/dataSource' if os.name != 'nt' else 'D:\\Studia\\MGU\\Data\\PS-Battles-master'\n",
    "path = dataSource\n",
    "os.chdir(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def verify_picture(pic):\n",
    "    try:\n",
    "        im = Image.open(pic)\n",
    "        im.verify()\n",
    "        im.close()\n",
    "        im = Image.open(pic)\n",
    "        im.resize((224,224))\n",
    "        im.convert('RGB')\n",
    "        if sum(im.convert(\"L\").getextrema()) in (0, 2):\n",
    "            return False\n",
    "        if os.stat(pic).st_size == 503:\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as err: \n",
    "        return False\n",
    "\n",
    "if os.name != 'nt': \n",
    "    out = verify_picture('../../MGU/Projekt/PS-Battles-master/originals/49366m.jpg')\n",
    "    print(out)\n",
    "else:\n",
    "    out = verify_picture('..\\..\\MGU\\Data\\PS-Battles-master\\originals\\49366m.jpg')\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "\n",
    "def clear():\n",
    "    clearPath = '/home/torak28/Desktop/Studia/MGU/Projekt/photos' if os.name != 'nt' else 'D:\\Studia\\MGU\\Data\\photos'\n",
    "\n",
    "    tmp = ['balanced', 'inbl', 'Oversampling', 'Undersampling']\n",
    "    tmp2 = ['test', 'valid']\n",
    "    tmp3 = ['org', 'ps']\n",
    "\n",
    "    slash = '/' if os.name != 'nt' else '\\\\'\n",
    "\n",
    "    for i in tmp:\n",
    "        for j in tmp2:\n",
    "            for k in tmp3:\n",
    "                rm = clearPath + slash + i + slash + j + slash + k + slash\n",
    "                rmtree(rm)\n",
    "                os.mkdir(rm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def stats():\n",
    "    tmp = ['balanced', 'inbl', 'Oversampling', 'Undersampling']\n",
    "    statPath = '/home/torak28/Desktop/Studia/MGU/Projekt/photos' if os.name != 'nt' else 'D:\\Studia\\MGU\\Data\\photos'\n",
    "    statPath = statPath + slash\n",
    "    \n",
    "    for i in tmp:\n",
    "\n",
    "        plt.figure(1, figsize = (15,8)) \n",
    "        plt.suptitle(i, fontsize=16)\n",
    "        \n",
    "        # Before\n",
    "        plt.subplot(231)  \n",
    "\n",
    "        org_files = len(os.listdir(dataSource + slash + 'originals' + slash))\n",
    "        ps_files = 0\n",
    "        for j in os.listdir(dataSource + slash + 'photoshops' + slash):\n",
    "            ps_files += len(os.listdir(dataSource + slash + 'photoshops' + slash + j))  \n",
    "        plt.bar(['org', 'ps'], [org_files, ps_files], align='center', alpha=0.5)  \n",
    "\n",
    "        plt.title('Org Data')  \n",
    "        plt.ylabel('Number of Files') \n",
    "    \n",
    "        # Testing\n",
    "        plt.subplot(232)  \n",
    "\n",
    "        org_files = len(os.listdir(statPath + i + slash + 'test' + slash + 'org' + slash))\n",
    "        ps_files = len(os.listdir(statPath + i + slash  + 'test' + slash + 'ps' + slash))  \n",
    "        lim = org_files if org_files >= ps_files else ps_files\n",
    "        plt.bar(['org', 'ps'], [org_files, ps_files], align='center', alpha=0.5)  \n",
    "\n",
    "        plt.title('Test')  \n",
    "        plt.ylabel('Number of Files') \n",
    "\n",
    "        # Valid\n",
    "        plt.subplot(233)  \n",
    "\n",
    "        org_files = len(os.listdir(statPath + i + slash  + 'valid' + slash + 'org' + slash))\n",
    "        ps_files = len(os.listdir(statPath + i + slash  + 'valid' + slash + 'ps' + slash))  \n",
    "        plt.bar(['org', 'ps'], [org_files, ps_files], align='center', alpha=0.5)  \n",
    "\n",
    "        plt.title('Valid')  \n",
    "        plt.ylabel('Number of Files')  \n",
    "        plt.ylim((0, lim)) \n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced Data(take first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_it_test(dst):\n",
    "\n",
    "    org = os.listdir('originals')\n",
    "    for i in org:\n",
    "        if verify_picture('originals' + slash + i):\n",
    "            name = os.path.splitext(i)[0]\n",
    "            tmp = os.listdir('photoshops' + slash + name)[:1]\n",
    "            for j in tmp:\n",
    "                if verify_picture('photoshops' + slash + name + slash + j):\n",
    "                    copyfile(os.path.abspath('photoshops' + slash + name + slash + j), os.path.abspath(dst + 'test' + slash + 'ps' + slash + j))\n",
    "                    copyfile(os.path.abspath('originals' + slash + i), os.path.abspath(dst + 'test' + slash + 'org' + slash + i))\n",
    "    all_files = len(os.listdir(dst + 'test' + slash + 'org' + slash)) + len(os.listdir(dst + 'test' + slash + 'ps' + slash))\n",
    "    org_files = len(os.listdir(dst + 'test' + slash + 'org' + slash))\n",
    "    ps_files = len(os.listdir(dst + 'test' + slash + 'ps' + slash))         \n",
    "    print(f'All files: {all_files}\\n\\tORG: {org_files}\\n\\tPSS: {ps_files}')\n",
    "\n",
    "import random\n",
    "\n",
    "def do_it_valid(dst='..' + slash + 'photos' + slash + 'balanced' + slash):\n",
    "    amount_of_org = round(len(os.listdir(dst + 'test' + slash + 'org' + slash)) / 4)\n",
    "    amount_of_ps = round(len(os.listdir(dst + 'test' + slash + 'ps' + slash)) / 4)\n",
    "    \n",
    "    org = os.listdir(dst + 'test' + slash + 'org' + slash)\n",
    "    ps = os.listdir(dst + 'test' + slash + 'ps' + slash)\n",
    "    \n",
    "\n",
    "    for _ in random.sample(org, k=amount_of_org):\n",
    "        copyfile(os.path.abspath(dst + 'test' + slash + 'org' + slash + _), dst + 'valid' + slash + 'org' + slash + _)\n",
    "\n",
    "    for _ in random.sample(ps, k=amount_of_ps):\n",
    "        copyfile(os.path.abspath(dst + 'test' + slash + 'ps' + slash + _), dst + 'valid' + slash + 'ps' + slash + _)\n",
    "\n",
    "    test = len(os.listdir(dst + 'test' + slash + 'org' + slash)) + len(os.listdir(dst + 'test' + slash + 'ps' + slash))\n",
    "    valid = len(os.listdir(dst + 'valid' + slash + 'org' + slash)) + len(os.listdir(dst + 'valid' + slash + 'ps' + slash))\n",
    "\n",
    "    print(f'Test data: {test}, Valid data: {valid}')\n",
    "\n",
    "# do_it_test(dst='..' + slash + 'photos' + slash + 'balanced' + slash)\n",
    "# do_it_valid(dst='..' + slash + 'photos' + slash + 'balanced' + slash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_it_test(dst):\n",
    "\n",
    "    org = os.listdir('originals')\n",
    "    for i in org:\n",
    "        if verify_picture('originals' + slash + i):\n",
    "            name = os.path.splitext(i)[0]\n",
    "            tmp = os.listdir('photoshops' + slash + name)\n",
    "            for j in tmp:\n",
    "                if verify_picture('photoshops' + slash + name + slash + j):\n",
    "                    copyfile(os.path.abspath('photoshops' + slash + name + slash + j), os.path.abspath(dst + 'test' + slash + 'ps' + slash + j))\n",
    "        copyfile(os.path.abspath('originals' + slash + i), os.path.abspath(dst + 'test' + slash + 'org' + slash + i))\n",
    "    all_files = len(os.listdir(dst + 'test' + slash + 'org' + slash)) + len(os.listdir(dst + 'test' + slash + 'ps' + slash))\n",
    "    org_files = len(os.listdir(dst + 'test' + slash + 'org' + slash))\n",
    "    ps_files = len(os.listdir(dst + 'test' + slash + 'ps' + slash))         \n",
    "    print(f'All files: {all_files}\\n\\tORG: {org_files}\\n\\tPSS: {ps_files}')\n",
    "    \n",
    "# do_it_test(dst='..' + slash + 'photos' + slash + 'inbl' + slash)\n",
    "# do_it_valid(dst='..' + slash + 'photos' + slash + 'inbl' + slash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_it_test(dst):\n",
    "\n",
    "    org = os.listdir('originals')\n",
    "    for i in org:\n",
    "        if verify_picture('originals' + slash + i):\n",
    "            name = os.path.splitext(i)[0]\n",
    "            tmp = [random.choice(os.listdir('photoshops' + slash + name))]\n",
    "            for j in tmp:\n",
    "                if verify_picture('photoshops' + slash + name + slash + j):\n",
    "                    copyfile(os.path.abspath('photoshops' + slash + name + slash + j), os.path.abspath(dst + 'test' + slash + 'ps' + slash + j))\n",
    "                    copyfile(os.path.abspath('originals' + slash + i), os.path.abspath(dst + 'test' + slash + 'org' + slash + i))\n",
    "    all_files = len(os.listdir(dst + 'test' + slash + 'org' + slash)) + len(os.listdir(dst + 'test' + slash + 'ps' + slash))\n",
    "    org_files = len(os.listdir(dst + 'test' + slash + 'org' + slash))\n",
    "    ps_files = len(os.listdir(dst + 'test' + slash + 'ps' + slash))         \n",
    "    print(f'All files: {all_files}\\n\\tORG: {org_files}\\n\\tPSS: {ps_files}')\n",
    "\n",
    "# do_it_test(dst='..' + slash + 'photos' + slash + 'Undersampling' + slash)\n",
    "# do_it_valid(dst='..' + slash + 'photos' + slash + 'Undersampling' + slash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "d:\\programs\\python37\\lib\\site-packages\\PIL\\Image.py:989: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from numpy import expand_dims\n",
    "\n",
    "import random\n",
    "\n",
    "clearPath = '/home/torak28/Desktop/Studia/MGU/Projekt/photos' if os.name != 'nt' else 'D:\\Studia\\MGU\\Data\\photos'\n",
    "\n",
    "tmp = ['Oversampling']\n",
    "tmp2 = ['test', 'valid']\n",
    "tmp3 = ['org', 'ps']\n",
    "\n",
    "slash = '/' if os.name != 'nt' else '\\\\'\n",
    "\n",
    "for i in tmp:\n",
    "    for j in tmp2:\n",
    "        for k in tmp3:\n",
    "            rm = clearPath + slash + i + slash + j + slash + k + slash\n",
    "            rmtree(rm)\n",
    "            os.mkdir(rm)\n",
    "\n",
    "def do_it_inbl(dst):\n",
    "    ver_org = []\n",
    "    org = os.listdir('originals')\n",
    "    for i in org:\n",
    "        if verify_picture('originals' + slash + i):\n",
    "            ver_org.append(i)\n",
    "#             name = os.path.splitext(i)[0]\n",
    "#             tmp = os.listdir('photoshops' + slash + name)\n",
    "#             for j in tmp:\n",
    "#                 if verify_picture('photoshops' + slash + name + slash + j):\n",
    "#                     copyfile(os.path.abspath('photoshops' + slash + name + slash + j), os.path.abspath(dst + 'test' + slash + 'ps' + slash + j))\n",
    "#         copyfile(os.path.abspath('originals' + slash + i), os.path.abspath(dst + 'test' + slash + 'org' + slash + i))\n",
    "    return ver_org\n",
    "        \n",
    "def do_it_test(dst):\n",
    "    \n",
    "    org = do_it_inbl(dst)\n",
    "    diff = len(os.listdir(dst + 'test' + slash + 'ps' + slash)) - len(os.listdir(dst + 'test' + slash + 'org' + slash))\n",
    "    imgs = []\n",
    "    for _ in range(diff):\n",
    "        imgs.append(random.choice(org))\n",
    "    del org\n",
    "    datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        brightness_range=[0.2,1.0],\n",
    "        zoom_range=[0.5,1.0]\n",
    "    )\n",
    "    print('Juz tutaj')\n",
    "    for img in imgs:\n",
    "        img = load_img(os.path.abspath('originals' + slash + img))\n",
    "        img = img_to_array(img)\n",
    "        img = expand_dims(img, 0)\n",
    "        imageGen = datagen.flow(img, batch_size=1, save_to_dir=dst + 'test' + slash + 'org',save_prefix=\"image\", save_format=\"jpg\")\n",
    "        xd = 0\n",
    "        for image in imageGen:\n",
    "            xd += 1\n",
    "            if xd == 1:\n",
    "                break\n",
    "    all_files = len(os.listdir(dst + 'test' + slash + 'org' + slash)) + len(os.listdir(dst + 'test' + slash + 'ps' + slash))\n",
    "    org_files = len(os.listdir(dst + 'test' + slash + 'org' + slash))\n",
    "    ps_files = len(os.listdir(dst + 'test' + slash + 'ps' + slash))         \n",
    "    print(f'All files: {all_files}\\n\\tORG: {org_files}\\n\\tPSS: {ps_files}')\n",
    "\n",
    "do_it_test(dst='..' + slash + 'photos' + slash + 'Oversampling' + slash)\n",
    "do_it_valid(dst='..' + slash + 'photos' + slash + 'Oversampling' + slash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exper1(top, pool, opt, loss, dataGen, pathFile):\n",
    "    out = []\n",
    "    print(f'MODEL with:')\n",
    "    print(f'\\tinclude_top: {top}')\n",
    "    print(f'\\tpooling: {pool}')\n",
    "    print(f'\\toptimizer: {opt}')\n",
    "    print(f'\\tloss_func: {loss}')\n",
    "    print(f'\\tdata_gen: {dataGen}')\n",
    "    \n",
    "    # Model\n",
    "    model = Sequential()\n",
    "    model.add(ResNet50(include_top = top, pooling = pool, weights = 'imagenet'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
    "    model.layers[0].trainable = False\n",
    "    model.summary()\n",
    "    model.compile(optimizer = opt, loss = loss, metrics = LOSS_METRICS)\n",
    "    \n",
    "    # Data Gen\n",
    "    image_size = IMAGE_RESIZE\n",
    "    if dataGen:\n",
    "        data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    else:\n",
    "        data_generator = ImageDataGenerator(\n",
    "            shear_range=10,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            preprocessing_function=preprocess_input\n",
    "        )\n",
    "    \n",
    "    # Data\n",
    "    path = pathFile\n",
    "    slash = '\\\\'\n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "        directory=path + slash + 'test' + slash,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_TRAINING,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = data_generator.flow_from_directory(\n",
    "        directory=path + slash + 'valid'+ slash,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_VALIDATION,\n",
    "        class_mode='categorical') \n",
    "    \n",
    "    # Callbacks\n",
    "    cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n",
    "    cb_checkpointer = ModelCheckpoint(filepath = '..' + slash + 'working' + slash + 'best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')\n",
    "    \n",
    "    # Fit\n",
    "    fit_history = model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "        callbacks=[cb_checkpointer, cb_early_stopper]\n",
    "    )\n",
    "    model.load_weights('..' + slash + 'working' + slash + 'best.hdf5')\n",
    "    name = 'DogsCats_Top_' + str(top) + '_Pool_' + pool + '_Opt_' + opt + '_Loss_' + loss + '_dataGen_' + str(dataGen)\n",
    "    model.save('..' + slash + 'working' + slash + name + '.h5')\n",
    "    \n",
    "    # Score v1\n",
    "    scoreRes = model.evaluate_generator(\n",
    "        generator=validation_generator\n",
    "    )\n",
    "    print(f'Accuracy = {scoreRes}')\n",
    "    tmp = {}\n",
    "    tmp[name] = scoreRes\n",
    "    out.append(tmp)\n",
    "    \n",
    "    # Score v2\n",
    "    plt.figure(1, figsize = (15,8)) \n",
    "    plt.subplot(221)  \n",
    "    plt.plot(fit_history.history['accuracy'])  \n",
    "    plt.plot(fit_history.history['val_accuracy'])  \n",
    "    plt.title('model accuracy')  \n",
    "    plt.ylabel('accuracy')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'valid']) \n",
    "    plt.subplot(222)  \n",
    "    plt.plot(fit_history.history['loss'])  \n",
    "    plt.plot(fit_history.history['val_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'valid']) \n",
    "    plt.show()\n",
    "    \n",
    "    # Show some predictions\n",
    "    test_generator = data_generator.flow_from_directory(\n",
    "        directory = path + slash + 'show' + slash,\n",
    "        target_size = (image_size, image_size),\n",
    "        batch_size = BATCH_SIZE_TESTING,\n",
    "        class_mode = None,\n",
    "        shuffle = False,\n",
    "        seed = 123\n",
    "    )\n",
    "    test_generator.reset()\n",
    "    pred = model.predict_generator(test_generator, steps = len(test_generator), verbose = 1)\n",
    "    predicted_class_indices = np.argmax(pred, axis = 1)\n",
    "    TEST_DIR = path + slash + 'show' + slash\n",
    "    f, ax = plt.subplots(5, 5, figsize = (15, 15))\n",
    "    for i in range(0,25):\n",
    "        imgBGR = cv2.imread(TEST_DIR + test_generator.filenames[i])\n",
    "        imgRGB = cv2.cvtColor(imgBGR, cv2.COLOR_BGR2RGB)\n",
    "        # a if condition else b\n",
    "        predicted_class = \"Dog\" if predicted_class_indices[i] else \"Cat\"\n",
    "        ax[i//5, i%5].imshow(imgRGB)\n",
    "        ax[i//5, i%5].axis('off')\n",
    "        ax[i//5, i%5].set_title(\"Predicted:{}\".format(predicted_class))    \n",
    "    plt.show()\n",
    "    \n",
    "    # End\n",
    "    print('---KONIEC---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Var + exp2 func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\\\Studia\\\\MGU\\\\Data\\\\photos'\n",
    "\n",
    "slash = '/' if os.name != 'nt' else '\\\\'\n",
    "\n",
    "folders = ['balanced', 'inbl', 'Oversampling', 'Undersampling']\n",
    "\n",
    "def exp2(pth):\n",
    "    exper1(False, 'avg', 'sgd', 'categorical_crossentropy', True, pth)\n",
    "#     exper1(False, 'avg', 'sgd', 'mean_squared_error', True, pth)\n",
    "#     exper1(False, 'avg', 'adam', 'mean_squared_error', True, pth)\n",
    "#     exper1(False, 'avg', 'adam', 'categorical_crossentropy', True, pth)\n",
    "#     exper1(False, 'avg', 'adadelta', 'categorical_crossentropy', True, pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    pathFile = path + slash + folder\n",
    "    exp2(pth=pathFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
